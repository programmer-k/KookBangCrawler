[국방일보-국방대 안보연구소 공동기획] 미래 국가안보를 위한 AI 기반 무기체계 개발스스로 목표물 선택·공격…정확한 데이터 학습 ‘관건’

인공지능 특이점 빨라지며 미래 국가안보 게임체인저 역할 부상
올바른 학습 위해 양질 데이터 확보 중요…특정 데이터 누락시 결과 부정적
시스템 테스트·정기적인 업데이트 함께 AI 시스템 문서화해야
 
인공지능(Artificial Intelligence)을 기반으로 모든 사물에 지능을 넣어서 인류의 삶을 증진시키는 디지털 혁신이 지속적으로 추진되고 있다. 과거에 사람들이 직접해야 했던 업무들을 인공지능을 지닌 자동화된 컴퓨터들이 대신 수행하므로 사람들은 편안함을 느끼고 동시에 효율성이 향상되고 있다. 이러한 기술 환경은 우리의 생활방식을 변화시키고 있으며, 우리의 미래 전쟁 방식도 변화시킬 것이다. 역사적으로 인류의 전쟁 방식은 인류가 일하고 생활하는 공간과 방식에 투영돼 왔으며 미래전은 첨단과학기술에 기반한 사이버전자전과 더불어 사이버인공지능전이 될 것이다.
 
인공지능은 ‘X+AI(Everything+AI)’라는 용어처럼 모든 분야에서 적용 가능한 범용 기술의 성격으로 발전하고 있다. 그로 인해 로봇이나 자율주행차 뿐만 아니라 다양한 산업 분야, 생활서비스, 금융서비스 형태로 적용 영역을 확장하고 있다. 또한, 인공지능 특이점(Singularity·인공지능이 비약적으로 발전해 인간의 지능을 뛰어넘는 기점)은 기존 예측인 2045년보다 빠른 2035년으로 예상하는 학자들도 있다. 인공지능의 한 분야인 기계 학습(Machine Learning)은 특정 영역에서 인간의 능력을 뛰어넘는 수준으로 미래 국가안보의 게임체인저로 인식되고 있다.


인공지능 이슈

의사결정의 불명확성=인공지능 기반 시스템의 가장 큰 특징은 의사 결정과 판단이 내부에서 어떻게 이뤄졌는지 알 수 없는 블랙박스 모형이라는 것이다. 이는 비선형적이고 매개변수가 최대 수천에서 수억 개에 이르는 알고리즘의 복잡성 때문이다. 이를 해결하기 위해 몇 년 전부터 설명 가능한 인공지능인 XAI(eXplainable Artificail Intelligence)에 대한 연구가 활발히 이뤄지고 있다.

데이터 편향성으로 인한 공정성 저하=인공지능의 올바른 학습을 위해서는 양질의 데이터 확보가 매우 중요하다. 데이터 품질에 대한 문제는 학습 데이터와 테스트 데이터의 선정과 비율에 관한 것부터 데이터의 편향 문제까지 포함된다. 학습 데이터의 편향으로 인한 공정성이 저하되는 문제는 꾸준히 발생하고 있는데 결국 데이터의 품질은 인공지능의 성공에 가장 중요한 요소라고 할 수 있다.

적대적 공격에 대한 문제=딥러닝 기반의 심층신경망을 이용한 모델에 대해서 적대적 공격(Adversarial Attack)이 가능하다. 학습 과정에서 악의적인 학습 데이터를 주입하는 중독 공격(Poisoning Attack)과 추론 과정에서 데이터를 교란해 인공지능을 속이는 회피 공격(Evasion Attack), 모델의 학습된 데이터를 추출하거나, 모델의 정보를 추출하는 탐색적 공격(Exploratory Attack)도 가능하다. 특히 정제되지 않은 오염 데이터는 의도하지 않은 중독 공격을 유발할 수 있어 주의가 필요하다.

인공지능의 윤리와 책임 문제=인공지능이 가지는 윤리적인 문제와 인공지능의 결과에 대한 책임 관계 문제에 대한 논의가 전 세계적으로 이뤄지고 있다. 인공지능 챗봇, 면접 프로그램, 범죄 예방 프로그램 등에서 성적 차별, 인종적 차별에 대한 윤리적 문제 등이 불거져 나왔다. 인공지능이 실행한 결과에 대한 책임은 누구에게 귀속되느냐에 대한 문제는 지속적인 논란이 되고 있다. 국방 분야 역시 인공지능이 무기체계에 적용되면서 가장 큰 논란을 불러 일으키는 주제는 인공지능을 장착한 치명적 자율무기(LAWs·Lethal Autonomous Weapons)에 대한 이슈다. LAWs는 인간의 개입 없이 시스템 스스로가 목표물을 선택하고 공격하도록 설계된 자율무기로 일부 사람들의 거부감은 있지만, 미국의 경우도 국가안보를 위해 인공지능 국방 활용에 힘쓰고 있다.


AI-기반 무기체계 개발

우리는 인공지능 기술을 이용한 선도적인 무기체계를 개발해 첨단기술 중심의 복잡한 미래전에 대비하고 영속되는 국가안보를 보유한 대한민국을 만들어야 한다. 이를 위한 AI-기반 무기체계 개발에 필요한 다섯 가지 사항을 제안한다.

첫째, 학습 데이터의 완전성이 필요하다. 입력 데이터의 품질이 낮거나 보정이 불량할 경우 학습의 품질이 저하될 수 있으며, 데이터를 여러 소스에서 가져온 경우 더 자주 문제가 발생한다. 누락된 데이터는 세 가지 주요 형태를 취할 수 있으며, 각 형태는 결과에 서로 다른 영향을 미치게 된다. 완전히 랜덤하게 누락된 경우는 모델의 확률적 성질에 따라 영향이 적으나 특정한 데이터만 누락되면 결과에 부정적인 영향을 끼치게 된다. 특정한 데이터의 특정 부분이 누락된 경우는 탐지가 매우 어려워 더 나쁜 경우로 이러한 데이터를 이용한 모델은 심각한 오류를 내재한다.

둘째, 학습 데이터 레이블링(인공지능을 만드는 데 필요한 학습 데이터를 입력하는 작업)이 정확해야 한다. 기계 학습은 학습 데이터가 정확하다고 가정하지만, 실제로 학습 데이터의 레이블이 100% 정확하지는 않다. 레이블 작업자가 버튼을 잘못 누르거나, 잘못된 지시로 인한 작업 실수를 하거나, 레이블 선정에 있어서 의견이 다르다거나, 고의적인 실수를 하는 등의 인간 작업자에 의한 실수가 반영된다. 레이블은 항상 하나 또는 두 개의 클래스로 나누는 단순한 분류가 아니며 복잡한 레이블링은 정확한 레이블에 대한 의문을 생기게 한다. 또한, 레이블링은 다양한 방법으로 수행될 수 있으며 내부 팀/외부 팀에 의한 레이블링, 클라우드 소싱된 레이블, 합성 데이터 생성, AI 기반 레이블링이 있다. 최근 인터넷 공간에서는 레이블링 아르바이트도 생겨나고 있다.

셋째, 학습 데이터와 목표 시스템에서 사용되는 데이터 분포를 유사하게 해야 한다. 머신러닝의 주요한 불확실성은 학습 데이터 분포와 목표 시스템 데이터 분포의 불일치다. 이 두 데이터 분포가 불일치할 경우 모델에 의해 제공된 예측에 결함이 생긴다. 일단 시스템이 작동되면, 예측된 운영 데이터가 변경됨에 따라 학습 데이터 분포와 목표 데이터 분포 사이의 거리가 종종 증가하므로 이상적으로는 시스템이 현재 운영 데이터 분포와 마지막으로 학습된 데이터 분포 간에 중대한 불일치를 감지하도록 시스템을 정기적으로 테스트해야 하고 불일치가 감지되면 업데이트된 학습 데이터를 사용해 시스템을 다시 학습시켜야 한다.

넷째, 개발하려는 무기체계 기능에 적합한 알고리즘과 모델을 선정해야 한다. 모델 선정과 모델 파라미터(두 개 이상의 변수 사이의 함수 관계를 간접적으로 표시할 때 사용하는 변수) 값의 부여는 과학(Science)과 예술(Art)의 사이에 있다. 문제 상황의 분석으로부터 최적의 파라미트 세트를 선택할 수 있는 명확한 접근방식은 없으므로 알고리즘 선택의 결정에 도움을 주는 것은 모델의 기능이 어떤 결과를 제공하는지, 알고리즘과 모델에 어떠한 데이터가 이용 가능한지, 어떤 기능적·비기능적인 요소를 만족해야 하는지에 대한 정보가 필요하다. 기능적인 관점에서 모델은 통상 분류, 예측, 군집 등을 제공하는데, 얼마만큼의 데이터가 이용 가능한지 알게 되면 특정한 알고리즘은 배제할 수 있을 것이다.

마지막으로 AI-기반 무기체계는 문서화가 필요하다. 무기체계 시스템 연구개발 절차에 따른 산출물과 같은 AI-기반 무기체계 개발의 문서화 기준이 현재는 없다. 장기간 사용되는 무기체계의 특성을 고려하면 이는 반드시 필요하다. 머신러닝 시스템이 점점 확산되고 중요한 분야에서 사용되고 있어 인공지능 시스템의 문서화를 위한 노력은 필수적이다. 문서화의 장점은 기능의 설명, 성능 특징에 대한 설명, 개발자와 사용자 간의 커뮤니케이션 촉진, 투명성 증대, 재사용성 증가 등이 있을 것이다.

강동수 교수 국방대학교 국가안보문제연구소 군사과학센터장

국방대 국가안전보장문제연구소가 발행하는 『안보현안분석 180호』에 게재된 글을 요약 발췌한 것으로 전문은 국가안전보장문제연구소 홈페이지에서 보실 수 있습니다.


자폭 드론 리비아 내전 등장…미국, 딥러닝 전투기 활용 시험
AI 무기 실전 배치하는 나라들

스텔스 무인기 XQ-58A 발키리에서 소형 무인기 알티우스 600을 분리하는 시험 장면. 사진 출처=미 공군

첨단기술 발달과 더불어 스스로 표적을 찾아 싸우는 무기의 시대가 다가오고 있다는 진단이 속속 나오고 있다.

미국 워싱턴포스트(WP)는 최근 주요 무력분쟁지에서 사용된 무기들을 분석해 이 같은 추세를 지난 7월 소개한 바 있다.

대표적인 사례가 리비아 내전에 등장한 자폭드론이다. 터키의 지원을 받는 리비아 정부군은 올해 봄 사막 전투에서 반군을 겨냥해 AI 기술을 접목한 이 무기를 사용했다.

취미나 영화 촬영에 사용될 법한 드론 수십개가 나타나 후퇴하는 병사나 차량을 향해 급강하한 뒤 접촉과 함께 폭발했다.

유엔과 전문가들은 이 드론들이 사람 조종을 받지 않고 스스로 대상을 탐지해 습격했다고 결론을 내렸다.

아제르바이잔도 작년 9월 아르메니아와의 전쟁에서 터키, 이스라엘이 개발한 두 종류의 자율살상 무인기를 썼다. 이들 무기는 크기가 작을 뿐 미군이 이라크, 아프가니스탄 등지에서 원격으로 조종하는 무인기와 비슷하게 생겼다. 그러나 이들 무기는 적군의 신호를 감지하면 스스로 돌진해 자폭한다는 자율성에서 차이가 있었다.

이스라엘은 탱크와 순찰 로봇에 활용하는 정찰 AI ‘아테나’를 개발하고 있다. 고출력 적외선과 레이더 센서를 활용해 전장의 데이터를 수집하고, 사람의 두뇌에 가까운 AI 모델이 상황에 맞는 판단을 내리는 구조다. 아테나는 사격 통제 기능과도 연결된다. 이스라엘의 최신형 장갑차 ‘카르멜 탱크’에 부착될 경우, 인간의 지시 없이도 스스로 돌아다니며 표적을 타격할 수 있다. 이스라엘 방위군(IDF)은 이르면 내년 실전 배치를 목표로 개발에 박차를 가하고 있다.

미국 역시 2018년 ‘AI에 대한 국가 안보위원회(NSCAI)’를 설치해 중국 견제를 위한 AI 무기 개발에 나서고 있다. 전투기에 딥러닝(학습을 통해 판단력을 계속 강화하는 기술) 능력이 있는 AI를 접목해 공중전에 활용하는 시험을 하기도 했다. 무인 전투기 ‘발키리’, 무인 잠수정 ‘오르카’ ‘씨헌터’ 등의 시험 테스트에도 잇따라 성공했다.

중국은 이미 2016년 AI 기술 기반 크루즈 미사일과 장거리대함미사일(LRASM) 개발에 착수했고 2027년까지 ‘AI 기반 인민해방군 현대화’를 공식화하고 ‘군민융합’을 강조하고 있다.

인명 살상 판단을 기계에 위탁하는 행위가 내포하는 비윤리적 성격으로 인해 논쟁의 대상이 될 수밖에 없다. 하지만 현대전이 점점 복잡해짐에 따라 AI 무기의 투입은 이제 ‘현실’이 돼가고 있다. 게다가 AI 기술은 한 번 벌어지면 기술 격차를 줄이기 어려운 특성이 있다. 우리가 AI 기반 무기체계 개발에 관심을 기울여야 하는 이유가 여기에 있다. 맹수열 기자


맹수열 기자 < guns13@dema.mil.kr >
< 저작권자 ⓒ 국방일보, 무단전재 및 재배포 금지 >
기사 공유하기
스크랩
0
댓글